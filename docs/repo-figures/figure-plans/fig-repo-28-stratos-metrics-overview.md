# fig-repo-28: STRATOS Metrics: Beyond AUROC

## Metadata

| Field | Value |
|-------|-------|
| **ID** | fig-repo-28 |
| **Title** | STRATOS Metrics: Beyond AUROC |
| **Complexity Level** | L2 (Statistical concept) |
| **Target Persona** | Biostatistician, Research Scientist |
| **Location** | docs/concepts-for-researchers.md |
| **Priority** | P0 |
| **Aspect Ratio** | 16:9 |

## Purpose

Explain the 5 STRATOS performance domainsâ€”why AUROC alone is insufficient for clinical model evaluation.

## Key Message

"AUROC measures discrimination but ignores calibration and clinical utility. STRATOS guidelines require ALL 5 domains for proper model evaluation."

## Visual Concept

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STRATOS METRICS: BEYOND AUROC                                â”‚
â”‚                    Van Calster et al. 2024                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  THE PROBLEM WITH AUROC ALONE                                                   â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                   â”‚
â”‚                                                                                 â”‚
â”‚  A model with AUROC = 0.90 could still:                                         â”‚
â”‚  âŒ Predict 50% probability when true risk is 5% (miscalibrated)                â”‚
â”‚  âŒ Be useless at clinical decision thresholds (no utility)                     â”‚
â”‚  âŒ Have unstable predictions across patients                                   â”‚
â”‚                                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  THE 5 STRATOS PERFORMANCE DOMAINS                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                             â”‚
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   1. DISCRIMINATION                    2. CALIBRATION                     â”‚ â”‚
â”‚  â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                    â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   "Can the model RANK patients?"       "Do predictions match reality?"    â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   ğŸ“Š AUROC (0.0 - 1.0)                 ğŸ“ˆ Calibration slope (ideal: 1.0)  â”‚ â”‚
â”‚  â”‚      Higher = better ranking            Slope < 1 = overfitting           â”‚ â”‚
â”‚  â”‚                                         Slope > 1 = underfitting          â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚                                        ğŸ“‰ Calibration intercept (ideal: 0)â”‚ â”‚
â”‚  â”‚                                         Measures systematic bias          â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚                                        âš–ï¸ O:E ratio (ideal: 1.0)          â”‚ â”‚
â”‚  â”‚                                         Observed / Expected events        â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   3. OVERALL PERFORMANCE               4. CLASSIFICATION                  â”‚ â”‚
â”‚  â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•               â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                  â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   "Discrimination + Calibration"       "At a specific threshold"          â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   ğŸ“Š Brier score (0.0 - 1.0)           ğŸ“Š Sensitivity, Specificity        â”‚ â”‚
â”‚  â”‚      Lower = better                       At chosen threshold             â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   ğŸ“Š Scaled Brier / IPA                âš ï¸ F1 NOT RECOMMENDED              â”‚ â”‚
â”‚  â”‚      Compares to null model               (ignores true negatives)        â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   5. CLINICAL UTILITY                                                     â”‚ â”‚
â”‚  â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                     â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   "Is the model useful for DECISIONS?"                                    â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   ğŸ“Š Net Benefit (threshold-specific)                                     â”‚ â”‚
â”‚  â”‚      Accounts for: benefits of true positives vs harms of false positives â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   ğŸ“ˆ Decision Curve Analysis (DCA)                                        â”‚ â”‚
â”‚  â”‚      Net benefit across threshold range (e.g., 5% - 40%)                  â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚   This is what actually matters for clinical deployment!                  â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  METRICS WE REPORT                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                              â”‚
â”‚                                                                                 â”‚
â”‚  â”‚ Domain         â”‚ Metric                â”‚ Reported â”‚                         â”‚
â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€ â”‚                         â”‚
â”‚  â”‚ Discrimination â”‚ AUROC with 95% CI      â”‚   âœ…     â”‚                         â”‚
â”‚  â”‚ Calibration    â”‚ Slope, Intercept, O:E  â”‚   âœ…     â”‚                         â”‚
â”‚  â”‚ Overall        â”‚ Brier, Scaled Brier    â”‚   âœ…     â”‚                         â”‚
â”‚  â”‚ Classification â”‚ Sens, Spec at 15%      â”‚   âœ…     â”‚                         â”‚
â”‚  â”‚ Clinical       â”‚ Net Benefit, DCA       â”‚   âœ…     â”‚                         â”‚
â”‚                                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  STRATOS SAYS DO NOT USE                                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                        â”‚
â”‚                                                                                 â”‚
â”‚  âŒ F1 Score (ignores true negatives)                                           â”‚
â”‚  âŒ AUPRC alone (ignores true negatives)                                        â”‚
â”‚  âŒ Accuracy at 0.5 threshold (wrong for prevalence â‰  50%)                      â”‚
â”‚  âŒ Youden index optimization (assumes equal costs)                             â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Content Elements

1. **Problem statement**: Why AUROC alone fails
2. **5 domains grid**: Discrimination, Calibration, Overall, Classification, Clinical
3. **Metrics table**: What we report for each domain
4. **Do not use list**: STRATOS-banned metrics

## Text Content

### Title Text
"STRATOS Metrics: 5 Domains for Proper Model Evaluation"

### Caption
Following STRATOS guidelines (Van Calster 2024), we report metrics across all 5 performance domains: discrimination (AUROC), calibration (slope, intercept, O:E ratio), overall (Brier, scaled Brier), classification (sensitivity, specificity at clinical threshold), and clinical utility (Net Benefit, DCA). AUROC alone is insufficientâ€”a well-discriminating model can still be poorly calibrated or clinically useless.

## Prompts for Nano Banana Pro

### Style Prompt
Five-domain grid showing STRATOS performance categories. Each domain as a card with icon, title, and key metrics. "Do not use" section with warning symbols. Clean, medical research aesthetic. Metrics table at bottom.

### Content Prompt
Create a STRATOS metrics overview:

**TOP - Problem**:
- "AUROC alone is insufficient"
- 3 bullet points of what AUROC misses

**MIDDLE - 5 Domain Grid**:
- 5 cards arranged in 2-3 layout
- Each with: Domain name, "What it measures", Key metrics
- Icons for each domain

**BOTTOM LEFT - Metrics Table**:
- Domain | Metric | Reported (checkmarks)

**BOTTOM RIGHT - Banned**:
- Red X marks: F1, AUPRC alone, Accuracy at 0.5, Youden

## Alt Text

STRATOS performance metrics diagram showing 5 evaluation domains. Discrimination: AUROC with CI. Calibration: slope, intercept, O:E ratio. Overall: Brier, scaled Brier. Classification: sensitivity, specificity at threshold. Clinical utility: Net Benefit, DCA. Table shows all metrics reported. Banned metrics: F1, AUPRC alone, accuracy at 0.5, Youden index.

## Status

- [x] Draft created
- [ ] Generated
- [ ] Placed in docs/concepts-for-researchers.md
