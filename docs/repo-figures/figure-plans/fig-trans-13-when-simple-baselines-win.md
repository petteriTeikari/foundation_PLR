# fig-trans-13: When Simple Baselines Win

**Status**: ğŸ“‹ PLANNED
**Tier**: 3 - Alternative Approaches
**Target Persona**: Data scientists, ML engineers, budget-conscious analysts

---

## 1. Metadata

| Field | Value |
|-------|-------|
| Figure ID | fig-trans-13 |
| Type | Decision framework with scenario guide |
| Style | 75% manuscript + 25% Economist |
| Dimensions | 14" Ã— 10" |
| Format | PDF (vector) + PNG (300 DPI) |

---

## 2. Purpose

Counter the "always use deep learning" narrative by providing a framework for when simple baselines (linear interpolation, moving average, ARIMA) are the right choiceâ€”based on data characteristics, constraints, and requirements.

---

## 3. Key Message

> "Foundation models have their place, but simple baselines often win. Know when simple is appropriate: small data, low SNR, interpretability requirements, or real-time constraints."

---

## 4. Literature Sources

| Source | Finding |
|--------|---------|
| Zeng 2023 | "Are Transformers Effective for Time Series Forecasting?" - Linear models competitive |
| Makridakis et al. 2022 | M5 Competition - Simple methods often competitive with deep learning |
| Hyndman & Athanasopoulos | "Forecasting: Principles and Practice" - Always benchmark simple first |

---

## 5. Visual Concept

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WHEN SIMPLE BASELINES WIN                                                 â”‚
â”‚  A Decision Framework                                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚  THE BASELINE SPECTRUM                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                      â”‚
â”‚                                                                            â”‚
â”‚  SIMPLE                                              COMPLEX               â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•     â”‚
â”‚                                                                            â”‚
â”‚  Constant/Mean    Linear    Moving    ARIMA    SAITS    MOMENT            â”‚
â”‚  Imputation       Interp    Average                     CSDI              â”‚
â”‚                                                                            â”‚
â”‚  â€¢ <1 sec compute â”‚         â”‚         â”‚         â”‚      â€¢ Minutes compute  â”‚
â”‚  â€¢ Fully interpretâ”‚         â”‚         â”‚         â”‚      â€¢ Black box        â”‚
â”‚  â€¢ No training    â”‚         â”‚         â”‚         â”‚      â€¢ GPU required     â”‚
â”‚  â€¢ Always stable  â”‚         â”‚         â”‚         â”‚      â€¢ Hyperparameters  â”‚
â”‚                                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚  WHEN TO USE SIMPLE BASELINES                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚                                                                            â”‚
â”‚  âœ“ Small data (< 1000 training samples)                                   â”‚
â”‚    â†’ Complex models overfit; linear methods generalize                     â”‚
â”‚                                                                            â”‚
â”‚  âœ“ Low signal-to-noise ratio                                              â”‚
â”‚    â†’ Foundation models may learn noise patterns                            â”‚
â”‚                                                                            â”‚
â”‚  âœ“ Interpretability required (clinical, regulatory)                        â”‚
â”‚    â†’ "Why did you predict 3.2mm?" needs a simple answer                   â”‚
â”‚                                                                            â”‚
â”‚  âœ“ Real-time constraints (< 100ms latency)                                â”‚
â”‚    â†’ Deep models too slow; linear is instant                              â”‚
â”‚                                                                            â”‚
â”‚  âœ“ Sparse missing data (< 5% missing)                                     â”‚
â”‚    â†’ Linear interpolation is often optimal for small gaps                  â”‚
â”‚                                                                            â”‚
â”‚  âœ“ Debugging/baseline establishment                                       â”‚
â”‚    â†’ Reviewers expect simple baseline comparisons                          â”‚
â”‚                                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚  WHEN TO USE FOUNDATION MODELS                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚                                                                            â”‚
â”‚  âœ“ Large training corpus available (> 10,000 samples)                      â”‚
â”‚  âœ“ Complex patterns (multi-scale periodicity, interactions)                â”‚
â”‚  âœ“ Transfer learning needed (pretrain once, apply many)                    â”‚
â”‚  âœ“ Long gaps (> 20% missing) with context-dependent reconstruction         â”‚
â”‚  âœ“ Zero-shot cross-domain application (no labeled data)                    â”‚
â”‚  âœ“ When simple baselines demonstrably fail                                 â”‚
â”‚                                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚  THE PRACTITIONER'S PROTOCOL                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                â”‚
â”‚                                                                            â”‚
â”‚  1. Always benchmark against simple baselines first                        â”‚
â”‚  2. If simple is within 10% of complex â†’ use simple                        â”‚
â”‚  3. If simple loses by > 20% â†’ consider foundation models                  â”‚
â”‚  4. Document the comparison (reviewers will ask)                           â”‚
â”‚  5. Consider compute/interpretability trade-offs                           â”‚
â”‚                                                                            â”‚
â”‚  "If you can't beat linear by a meaningful margin,                         â”‚
â”‚   you don't need deep learning."                                           â”‚
â”‚                                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚  COMPARISON DIMENSIONS                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                     â”‚
â”‚                                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                                                                   â”‚     â”‚
â”‚  â”‚  Dimension        â”‚ Simple         â”‚ Foundation Model            â”‚     â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚     â”‚
â”‚  â”‚  Compute time     â”‚ Seconds        â”‚ Minutes to hours            â”‚     â”‚
â”‚  â”‚  Interpretability â”‚ Full           â”‚ Limited (attention maps)    â”‚     â”‚
â”‚  â”‚  Training data    â”‚ None/minimal   â”‚ Thousands of samples        â”‚     â”‚
â”‚  â”‚  Hyperparameters  â”‚ Few/none       â”‚ Many (architecture + HP)    â”‚     â”‚
â”‚  â”‚  Deployment       â”‚ CPU anywhere   â”‚ GPU often required          â”‚     â”‚
â”‚  â”‚  Reproducibility  â”‚ Deterministic  â”‚ Seed-dependent              â”‚     â”‚
â”‚  â”‚                                                                   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. Text Content

### Title
"When Simple Baselines Win"

### Caption
"Simple baselines often outperform complex models when data is limited, noise is high, or interpretability is required. The practitioner's protocol: benchmark against simple methods first, use complex only if they beat simple by a meaningful margin (>10-20%), and always document the comparison. Simple methods offer advantages in compute, interpretability, and deployment that foundation models cannot match."

---

## 7. Prompts for Nano Banana Pro

### Primary Prompt
```
Create a decision framework showing when simple baselines beat foundation models.

TOP - Baseline spectrum:
Simple (constant, linear, moving avg) â†’ Complex (ARIMA, SAITS, MOMENT)
Show trade-offs at each end

MIDDLE LEFT - "When to use simple" checklist:
- Small data
- Low SNR
- Interpretability required
- Real-time constraints
- Sparse missing data
- Baseline establishment

MIDDLE RIGHT - "When to use FMs" checklist:
- Large training corpus
- Complex patterns
- Transfer learning
- Long gaps
- Zero-shot application

BOTTOM - Practitioner's protocol:
5-step process for method selection

TABLE - Comparison dimensions:
Compute, interpretability, training, hyperparams, deployment, reproducibility

Style: Framework-focused, no specific performance numbers
```

---

## 8. Alt Text

"Decision framework for choosing between simple baselines and foundation models. Top shows spectrum from simple (constant, linear, moving average) to complex (ARIMA, SAITS, MOMENT). Left checklist shows scenarios favoring simple: small data, low SNR, interpretability, real-time, sparse gaps. Right checklist shows FM scenarios: large corpus, complex patterns, transfer learning, long gaps, zero-shot. Bottom shows 5-step practitioner's protocol for method selection. Table compares dimensions: compute, interpretability, training, hyperparameters, deployment, reproducibility."

---

## 9. Status

- [x] Draft created
- [x] Revised to focus on decision framework, not specific results
- [ ] Generated
- [ ] Placed in documentation

## Note

Specific performance comparisons from experiments are in the manuscript, not this figure.
