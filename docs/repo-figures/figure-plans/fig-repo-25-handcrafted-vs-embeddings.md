# fig-repo-25: Two Featurization Paths: Handcrafted Features vs MOMENT Embeddings

## Metadata

| Field | Value |
|-------|-------|
| **ID** | fig-repo-25 |
| **Title** | Two Featurization Paths |
| **Complexity Level** | L2-L3 (Architecture) |
| **Target Persona** | ML Engineer, Research Scientist |
| **Location** | docs/user-guide/, ARCHITECTURE.md |
| **Priority** | P2 |
| **Aspect Ratio** | 16:10 |

## Purpose

Show the two alternative featurization paths in the repository: handcrafted physiological features (defined in YAML configs) vs MOMENT embeddings (using representation learning). Focus on CODE and CONFIG, not results.

## Key Message

"The repository supports two featurization methods: handcrafted features (YAML-configured time-window statistics) and MOMENT embeddings (768-d latent representations). Choose based on your use case."

## Code Architecture (Verified from Repository)

### Path 1: Handcrafted Features

**Config location**: `configs/PLR_FEATURIZATION/`

```yaml
# configs/PLR_FEATURIZATION/featuresSimple.yaml
FEATURES_METADATA:
  name: 'simple'
  feature_method: 'handcrafted_features'
FEATURES:
  MAX_CONSTRICTION:
    time_from: 'onset'
    time_start: 0
    time_end: 15
    measure: 'amplitude'
    stat: 'min'
  PHASIC:
    time_from: 'onset'
    time_start: 0
    time_end: 5
    measure: 'amplitude'
    stat: 'min'
  SUSTAINED:
    time_from: 'offset'
    time_start: -5
    time_end: 0
    measure: 'amplitude'
    stat: 'min'
  PIPR_AUC:
    time_from: 'offset'
    time_start: 0
    time_end: 12
    measure: 'amplitude'
    stat: 'AUC'
```

**Code path**:
```
src/featurization/
â”œâ”€â”€ flow_featurization.py           # Prefect flow entry point
â”œâ”€â”€ featurize_PLR.py                 # Main orchestration
â”‚   â””â”€â”€ featurize_subject()          # Per-subject extraction
â”œâ”€â”€ featurizer_PLR_subject.py        # Feature computation
â”‚   â””â”€â”€ get_features_per_color()     # Per-color feature extraction
â””â”€â”€ subflow_handcrafted_featurization.py
```

### Path 2: MOMENT Embeddings

**Config location**: `configs/PLR_EMBEDDING/MOMENT.yaml`

```yaml
# configs/PLR_EMBEDDING/MOMENT.yaml
MOMENT:
  MODEL:
    pretrained_model_name_or_path: 'AutonLab/MOMENT-1-large'
    model_kwargs:
      task_name: "reconstruction"  # or "embedding" for embeddings
  LINEAR_PROBING:
    task_name: "anomaly-detection"
    finetuning_mode: "linear-probing"
```

**Code path**:
```
src/featurization/embedding/
â”œâ”€â”€ moment_embedding.py              # Main embedding extraction
â”‚   â””â”€â”€ import_moment_embedder()     # Load MOMENT for embeddings
â”‚   â””â”€â”€ get_embeddings_per_split()   # Compute 768-d vectors
â””â”€â”€ dim_reduction.py                 # Optional PCA post-processing
```

**MOMENT Reference**: [Representation Learning Tutorial](https://github.com/moment-timeseries-foundation-model/moment/blob/main/tutorials/representation_learning.ipynb)

## Visual Concept

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TWO FEATURIZATION PATHS                                             â”‚
â”‚              configs/PLR_FEATURIZATION/ vs configs/PLR_EMBEDDING/                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                        â”‚  Imputed PLR Signal             â”‚                       â”‚
â”‚                        â”‚  (from Stage 2: Imputation)     â”‚                       â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                        â”‚                                         â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                          â–¼                           â–¼                           â”‚
â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—   â”‚
â”‚  â•‘  PATH 1: HANDCRAFTED FEATURES     â•‘  â•‘  PATH 2: MOMENT EMBEDDINGS        â•‘   â”‚
â”‚  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£   â”‚
â”‚  â•‘                                   â•‘  â•‘                                   â•‘   â”‚
â”‚  â•‘  ğŸ“ Config:                       â•‘  â•‘  ğŸ“ Config:                       â•‘   â”‚
â”‚  â•‘  configs/PLR_FEATURIZATION/       â•‘  â•‘  configs/PLR_EMBEDDING/MOMENT.yamlâ•‘   â”‚
â”‚  â•‘  â”œâ”€â”€ featuresSimple.yaml          â•‘  â•‘                                   â•‘   â”‚
â”‚  â•‘  â””â”€â”€ featuresBaseline.yaml        â•‘  â•‘  MODEL:                           â•‘   â”‚
â”‚  â•‘                                   â•‘  â•‘    pretrained_model_name_or_path: â•‘   â”‚
â”‚  â•‘  FEATURES:                        â•‘  â•‘      'AutonLab/MOMENT-1-large'    â•‘   â”‚
â”‚  â•‘    MAX_CONSTRICTION:              â•‘  â•‘    model_kwargs:                  â•‘   â”‚
â”‚  â•‘      time_from: 'onset'           â•‘  â•‘      task_name: "embedding"       â•‘   â”‚
â”‚  â•‘      time_start: 0                â•‘  â•‘                                   â•‘   â”‚
â”‚  â•‘      time_end: 15                 â•‘  â•‘  See MOMENT tutorial:             â•‘   â”‚
â”‚  â•‘      measure: 'amplitude'         â•‘  â•‘  representation_learning.ipynb    â•‘   â”‚
â”‚  â•‘      stat: 'min'                  â•‘  â•‘                                   â•‘   â”‚
â”‚  â•‘    PIPR_AUC:                      â•‘  â•Ÿâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¢   â”‚
â”‚  â•‘      stat: 'AUC'                  â•‘  â•‘  ğŸ“‚ Code:                         â•‘   â”‚
â”‚  â•‘      ...                          â•‘  â•‘  src/featurization/embedding/     â•‘   â”‚
â”‚  â•Ÿâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¢  â•‘  â””â”€â”€ moment_embedding.py          â•‘   â”‚
â”‚  â•‘  ğŸ“‚ Code:                         â•‘  â•‘      â””â”€â”€ get_embeddings_per_split â•‘   â”‚
â”‚  â•‘  src/featurization/               â•‘  â•‘                                   â•‘   â”‚
â”‚  â•‘  â””â”€â”€ featurize_PLR.py             â•‘  â•‘  Output: 768-d latent vector      â•‘   â”‚
â”‚  â•‘      â””â”€â”€ featurizer_PLR_subject   â•‘  â•‘  (or reduced via PCA)             â•‘   â”‚
â”‚  â•‘                                   â•‘  â•‘                                   â•‘   â”‚
â”‚  â•‘  Output: N features               â•‘  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚  â•‘  (configured in YAML)             â•‘                                          â”‚
â”‚  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                          â”‚
â”‚                                                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  HANDCRAFTED FEATURE TYPES                                                       â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                        â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                          â”‚   â”‚
â”‚  â”‚  Feature         â”‚ time_from â”‚ time_start â”‚ time_end â”‚ stat            â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚   â”‚
â”‚  â”‚  MAX_CONSTRICTION â”‚ onset     â”‚ 0s         â”‚ 15s      â”‚ min amplitude  â”‚   â”‚
â”‚  â”‚  PHASIC          â”‚ onset     â”‚ 0s         â”‚ 5s       â”‚ min amplitude  â”‚   â”‚
â”‚  â”‚  SUSTAINED       â”‚ offset    â”‚ -5s        â”‚ 0s       â”‚ min amplitude  â”‚   â”‚
â”‚  â”‚  PIPR            â”‚ offset    â”‚ 0s         â”‚ 15s      â”‚ min amplitude  â”‚   â”‚
â”‚  â”‚  PIPR_AUC        â”‚ offset    â”‚ 0s         â”‚ 12s      â”‚ AUC            â”‚   â”‚
â”‚  â”‚  BASELINE        â”‚ onset     â”‚ -5s        â”‚ 0s       â”‚ median         â”‚   â”‚
â”‚  â”‚                                                                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                  â”‚
â”‚  Features are computed per light color (Blue, Red) â†’ 2Ã— the feature count       â”‚
â”‚                                                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MOMENT EMBEDDING MODES                                                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                          â”‚
â”‚                                                                                  â”‚
â”‚  From https://github.com/moment-timeseries-foundation-model/moment:             â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                                            â”‚ â”‚
â”‚  â”‚  task_name         â”‚ Use case                    â”‚ Output dimension       â”‚ â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”‚
â”‚  â”‚  "embedding"       â”‚ Representation learning     â”‚ 768-d (large model)    â”‚ â”‚
â”‚  â”‚  "reconstruction"  â”‚ Imputation/anomaly          â”‚ Reconstructed signal   â”‚ â”‚
â”‚  â”‚  "forecasting"     â”‚ Future prediction           â”‚ Forecasted values      â”‚ â”‚
â”‚  â”‚                                                                            â”‚ â”‚
â”‚  â”‚  Our repo uses "embedding" mode for featurization via:                     â”‚ â”‚
â”‚  â”‚  import_moment_embedder() â†’ model(x_enc=x) â†’ outputs.embeddings            â”‚ â”‚
â”‚  â”‚                                                                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                  â”‚
â”‚  Optional: PCA dimensionality reduction (dim_reduction.py)                       â”‚
â”‚                                                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CHOOSING A PATH                                                                 â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                                 â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                                            â”‚ â”‚
â”‚  â”‚  Choose HANDCRAFTED when:        â”‚  Choose EMBEDDINGS when:               â”‚ â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”‚
â”‚  â”‚  â€¢ Domain knowledge available     â”‚  â€¢ Exploring new signals              â”‚ â”‚
â”‚  â”‚  â€¢ Interpretability required      â”‚  â€¢ Transfer learning scenario         â”‚ â”‚
â”‚  â”‚  â€¢ Small sample size (N<500)      â”‚  â€¢ Large-scale datasets               â”‚ â”‚
â”‚  â”‚  â€¢ Regulatory/clinical context    â”‚  â€¢ Rapid prototyping                  â”‚ â”‚
â”‚  â”‚                                                                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                  â”‚
â”‚  Note: Results comparison is in the manuscript, not this repository.            â”‚
â”‚                                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Content Elements

1. **Branching diagram**: PLR signal â†’ two featurization paths
2. **Path 1 details**: Config location, YAML structure, code path
3. **Path 2 details**: MOMENT config, task_name modes, code path
4. **Feature types table**: Time-window based handcrafted features
5. **MOMENT modes table**: embedding vs reconstruction vs forecasting
6. **Decision guide**: When to choose each path

## Text Content

### Title Text
"Two Featurization Paths: Handcrafted Features vs MOMENT Embeddings"

### Caption
The repository supports two featurization paths. Path 1 (Handcrafted): Configure time-window statistics in `configs/PLR_FEATURIZATION/*.yaml` (MAX_CONSTRICTION, PHASIC, SUSTAINED, PIPR_AUC). Path 2 (Embeddings): Use MOMENT foundation model in "embedding" mode via `configs/PLR_EMBEDDING/MOMENT.yaml` to extract 768-dimensional latent representations. See MOMENT's [representation_learning.ipynb](https://github.com/moment-timeseries-foundation-model/moment/blob/main/tutorials/representation_learning.ipynb) for details.

## Sources

- [MOMENT Repository](https://github.com/moment-timeseries-foundation-model/moment)
- [MOMENT Representation Learning Tutorial](https://github.com/moment-timeseries-foundation-model/moment/blob/main/tutorials/representation_learning.ipynb)
- `configs/PLR_FEATURIZATION/featuresSimple.yaml`
- `configs/PLR_EMBEDDING/MOMENT.yaml`
- `src/featurization/featurize_PLR.py`
- `src/featurization/embedding/moment_embedding.py`

## Prompts for Nano Banana Pro

### Style Prompt
Architecture diagram with two parallel paths. Config files shown as code blocks. Directory tree structures. Tables for feature definitions and MOMENT modes. Decision matrix at bottom. Technical documentation style, no results/metrics.

### Content Prompt
Create a two-path featurization diagram:

**TOP - Branching Point**:
- Input: "Imputed PLR Signal"
- Two arrows leading to Path 1 and Path 2

**LEFT - Path 1 (Handcrafted)**:
- Config: configs/PLR_FEATURIZATION/
- YAML snippet showing feature definitions
- Code: src/featurization/featurize_PLR.py

**RIGHT - Path 2 (Embeddings)**:
- Config: configs/PLR_EMBEDDING/MOMENT.yaml
- MOMENT task_name: "embedding"
- Code: src/featurization/embedding/moment_embedding.py
- Link to MOMENT repo tutorial

**MIDDLE - Feature Types Table**:
- Handcrafted features: time_from, time_start, time_end, stat

**BOTTOM - MOMENT Modes Table**:
- embedding, reconstruction, forecasting

**FOOTER - Decision Guide**:
- When to choose each path (no performance metrics)

## Alt Text

Architecture diagram showing two featurization paths. Path 1 (Handcrafted): Config at configs/PLR_FEATURIZATION with YAML-defined time-window features (MAX_CONSTRICTION, PHASIC, SUSTAINED, PIPR_AUC), code at src/featurization/featurize_PLR.py. Path 2 (Embeddings): Config at configs/PLR_EMBEDDING/MOMENT.yaml using task_name "embedding", code at src/featurization/embedding/moment_embedding.py producing 768-d vectors. Tables show feature definitions and MOMENT modes. Decision guide at bottom explains when to use each path.

## Status

- [x] Draft created
- [x] Updated to focus on code/config, not results
- [ ] Generated
- [ ] Placed in docs/user-guide/
