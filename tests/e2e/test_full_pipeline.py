"""
End-to-end pipeline test: MLflow -> DuckDB -> CSV -> R -> Figure

This test validates the entire pipeline produces correct output.
"""

import pytest
from pathlib import Path
from datetime import datetime, timedelta

import duckdb
import pandas as pd


class TestFullPipeline:
    """E2E validation of the full pipeline."""

    DB_PATH = (
        Path(__file__).parent.parent.parent
        / "data"
        / "public"
        / "foundation_plr_results.db"
    )
    CSV_PATH = (
        Path(__file__).parent.parent.parent
        / "data"
        / "r_data"
        / "essential_metrics.csv"
    )
    FIGURE_PATH = (
        Path(__file__).parent.parent.parent
        / "figures"
        / "generated"
        / "ggplot2"
        / "main"
        / "fig_forest_combined.png"
    )

    @pytest.fixture(autouse=True)
    def _require_production_data(self):
        """Skip all tests in this class when production data is unavailable."""
        if not self.DB_PATH.exists():
            pytest.skip(f"Production DB not found: {self.DB_PATH}. Run: make extract")

    def test_database_exists(self):
        """Extraction output exists."""
        assert self.DB_PATH.exists(), (
            f"Database not found: {self.DB_PATH}. Run: make extract"
        )

    def test_database_has_essential_metrics_table(self):
        """Database has the essential_metrics table."""
        conn = duckdb.connect(str(self.DB_PATH), read_only=True)
        tables = conn.execute("SHOW TABLES").fetchall()
        table_names = [t[0] for t in tables]
        conn.close()

        assert "essential_metrics" in table_names, (
            f"essential_metrics table not found. Available tables: {table_names}"
        )

    def test_csv_export_exists(self):
        """CSV export for R exists."""
        if not self.CSV_PATH.exists():
            pytest.skip(f"CSV not found: {self.CSV_PATH}. Run: make analyze")

    def test_csv_has_data(self):
        """CSV export has rows and required columns."""
        if not self.CSV_PATH.exists():
            pytest.skip(f"CSV not found: {self.CSV_PATH}. Run: make analyze")
        csv_df = pd.read_csv(self.CSV_PATH)

        assert len(csv_df) > 0, "CSV export is empty"
        required_cols = ["outlier_method", "imputation_method", "classifier", "auroc"]
        for col in required_cols:
            assert col in csv_df.columns, f"CSV missing required column: {col}"

    def test_ground_truth_auroc_in_database(self):
        """Ground truth AUROC is 0.911 +/- 0.002 (handcrafted features, CatBoost)."""
        conn = duckdb.connect(str(self.DB_PATH), read_only=True)
        result = conn.execute(
            """
            SELECT auroc FROM essential_metrics
            WHERE outlier_method = 'pupil-gt'
              AND imputation_method = 'pupil-gt'
              AND UPPER(classifier) = 'CATBOOST'
              AND featurization LIKE 'simple%'
        """
        ).fetchone()
        conn.close()

        if result is None:
            pytest.fail("Ground truth config not found in database")

        auroc = result[0]
        assert 0.909 <= auroc <= 0.913, f"GT AUROC {auroc} outside [0.909, 0.913]"

    def test_handcrafted_features_present(self):
        """Handcrafted features (simple*) are present in database."""
        conn = duckdb.connect(str(self.DB_PATH), read_only=True)
        simple_count = conn.execute(
            """
            SELECT COUNT(*) FROM essential_metrics
            WHERE featurization LIKE 'simple%'
        """
        ).fetchone()[0]
        conn.close()

        assert simple_count > 0, "No handcrafted (simple*) features found in database"

    def test_figure_exists(self):
        """Forest plot figure exists."""
        if not self.FIGURE_PATH.exists():
            pytest.skip(f"Figure not found: {self.FIGURE_PATH}. Run: make analyze")

    def test_figure_not_stale(self):
        """Figure is newer than database (or within 30 days).

        Figures are regenerated by `make analyze` which runs R scripts.
        The DB may be updated independently (e.g., metadata changes).
        A 30-day window prevents false failures from minor DB touches.
        """
        if not self.FIGURE_PATH.exists():
            pytest.skip(f"Figure not found: {self.FIGURE_PATH}. Run: make analyze")
        fig_mtime = datetime.fromtimestamp(self.FIGURE_PATH.stat().st_mtime)
        db_mtime = datetime.fromtimestamp(self.DB_PATH.stat().st_mtime)

        assert fig_mtime > db_mtime - timedelta(days=30), (
            f"Figure is STALE: generated {fig_mtime}, database updated {db_mtime}. "
            f"Run: make analyze"
        )


class TestDataQuality:
    """Additional data quality checks."""

    DB_PATH = (
        Path(__file__).parent.parent.parent
        / "data"
        / "public"
        / "foundation_plr_results.db"
    )

    @pytest.fixture(autouse=True)
    def _require_production_data(self):
        """Skip all tests in this class when production data is unavailable."""
        if not self.DB_PATH.exists():
            pytest.skip(f"Production DB not found: {self.DB_PATH}. Run: make extract")

    def test_no_null_auroc(self):
        """AUROC should never be NULL."""
        conn = duckdb.connect(str(self.DB_PATH), read_only=True)
        null_count = conn.execute(
            "SELECT COUNT(*) FROM essential_metrics WHERE auroc IS NULL"
        ).fetchone()[0]
        conn.close()

        assert null_count == 0, f"Found {null_count} rows with NULL AUROC"

    def test_auroc_in_valid_range(self):
        """AUROC should be between 0 and 1."""
        conn = duckdb.connect(str(self.DB_PATH), read_only=True)
        invalid = conn.execute(
            """
            SELECT COUNT(*) FROM essential_metrics
            WHERE auroc < 0 OR auroc > 1
        """
        ).fetchone()[0]
        conn.close()

        assert invalid == 0, f"Found {invalid} rows with AUROC outside [0, 1]"

    def test_ci_bounds_valid(self):
        """CI bounds should satisfy: lower <= mean <= upper (excluding NULL/NaN)."""
        conn = duckdb.connect(str(self.DB_PATH), read_only=True)
        # Only check rows that have valid (non-NULL, non-NaN) CI bounds
        invalid = conn.execute(
            """
            SELECT COUNT(*) FROM essential_metrics
            WHERE auroc_ci_lower IS NOT NULL
              AND auroc_ci_upper IS NOT NULL
              AND NOT isnan(auroc_ci_lower)
              AND NOT isnan(auroc_ci_upper)
              AND (auroc_ci_lower > auroc OR auroc_ci_upper < auroc)
        """
        ).fetchone()[0]
        conn.close()

        assert invalid == 0, f"Found {invalid} rows with invalid CI bounds"

    def test_no_duplicate_configs(self):
        """No duplicate (outlier, imputation, classifier, featurization) combinations."""
        conn = duckdb.connect(str(self.DB_PATH), read_only=True)
        duplicates = conn.execute(
            """
            SELECT outlier_method, imputation_method, classifier, featurization, COUNT(*) as cnt
            FROM essential_metrics
            GROUP BY outlier_method, imputation_method, classifier, featurization
            HAVING cnt > 1
        """
        ).fetchall()
        conn.close()

        assert len(duplicates) == 0, f"Found duplicate configs: {duplicates}"
