TabM:
  # https://github.com/yandex-research/tabm
  # https://arxiv.org/abs/2410.24210
  # https://github.com/yandex-research/tabm/blob/main/tabm_reference.py
  # https://github.com/yandex-research/tabm/blob/main/example.ipynb
  arch_type: 'tabm-mini'
  n_epochs: 100
  patience: 16
  batch_size: 256
  # from here below, could be on MODEL as well to match other models
  # see TabM_hyperparam_space.yaml for briefs empirical findings
  d_block: 32
  d_embedding: 8
  k: 8
  dropout: 0.1
  lr: 0.02
  weight_decay: 0.003
  MODEL:
    WEIGHING:
      # None of these work with TabM, but every method requires these atm for weights computation
      weigh_the_features: False # feature_weights
      # TODO! how to use this in production?) we are now logging the sum of weights for each subject
      #  in the training set, and we could compute the weights for incoming samples, and compare how they
      #  compare to the training set, is the subject with more uncertain features or not?
      weigh_the_samples: False # sample_weight
      # https://stats.stackexchange.com/a/618758/294507
      weigh_the_classes: False # scale_pos_weight
      # How to create weights for the features
      weights_creation_method: 'inverse_of_variance'
      weights_sample_creation_method: 'normalize_mean'
      weights_nan_weight_fixing: 'unity'
    SAVE:
      # this is rather large (compared to other models used here), so to save some MLflow artifacts
      # space, we can skip the model pickling (as this was not a winning model anyway)
      skip_model_export: True